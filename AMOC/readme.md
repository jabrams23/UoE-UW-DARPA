Code to train a DL model to AMOC 4 box model

Analysis concerning the AMOC tipping point centers around the use of deep learning (DL) to predict the movement towards collapse in a 4-box model as detailed by Gnanadesikan et al.. The model code has been written in two ways, the first two of which 4box_AMOC_null_training_set.R and 4box_AMOC_tip_training_set.R randomly sample the parameters altered in the original paper from a uniform distribution. The code is set up to run an ensemble of 10000 members and we create two ensembles, one where the circulation is not approaching tipping (sampling a freshwater forcing value), and the other where is a movement towards tipping (sampling two freshwater forcing values). The script sw_dens_funcs.R is used in the model to calculate seawater density.

Previous analysis has shown that the DL models created by Bury et al. perform poorly at differentiating between those ensemble members that are forced slowly towards tipping, and those that remain stable. This has led us to create a DL model to determine how far away from tipping the tipping ensemble members are. Alongside each of the parameter combinations in the tipping dataset, a simulation is run with no additive noise, that continues to extrapolate the increase in freshwater forcing to determine when tipping will occur with that specific set of parameters. The script to do this (4box_AMOC_dist_from_tipping.R) takes the saved output of 4box_AMOC_tip_training_set.R as input. A caveat here is that this shows when the equilibrium run would collapse, with additive noise most likely causing an earlier tip in practice.

Generating training data
Each ensemble member runs for 1000 years to determine the equilibrium, then runs for 375 years with stochastic additive noise (of randomly sampled level) and the change in freshwater forcing (for those tipping ensemble members) added. Sometimes a member of the ensemble that uses the set of ‘AMOC off’ equations may tip due to the combination of parameters and tip in the equilibrium phase, or due to a combination of the freshwater forcing and additive noise level. In these cases, the ensemble member is rejected and a new set of parameters are sampled to run a new member. 

Examining this tipping dataset showed a strongly exponential distribution of times until the ensemble members would tip, leading to the targets for the DL needing to be logged. To complement this, we also have created code (4box_AMOC_tip_training_set_ver2.R) to produce an ensemble using the standard parameter values. With these, we can determine the critical value of freshwater forcing needed to tip the model, from which we can sample the rate of change in freshwater forcing to create an ensemble member that is a required distance away from tipping. As such, we can create a uniform distribution of targets for the DL.

Training the neural network
A CNN-LSTM neural network coded in Tensorflow has been created to determine the distance from tipping in both cases. In this case we split the data into training (70%), validation (15%) and test (15%) sets. An example of the DL training can be found in CNN_LSTM_eg.R. A different number of CNN and LSTM layers have been tested to determine a best validation fit on the model ensemble created by the first instance detailed above. For the targets that form a uniform distribution, exploration is currently being undertaken. It is hoped that the results from this will inform a better DL model fit across both ensembles.